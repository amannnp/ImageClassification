# -*- coding: utf-8 -*-
"""mainscript.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PlRoB7_qVzZGPYLvDB1KodCGVBlOF6NW
"""

import tensorflow as tf
from tensorflow.keras.datasets import cifar100
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Add, GlobalAveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# imp : put early stopping ; last time accuracy fell

(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')
X_train, X_test = X_train / 255.0, X_test / 255.0
y_train = to_categorical(y_train, 100)
y_test = to_categorical(y_test, 100)

datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    shear_range=0.1,
    fill_mode='nearest'
)
datagen.fit(X_train)

def residual_block(x, filters, kernel_size=3, strides=1, weight_decay=1e-4):
    shortcut = x
    x = Conv2D(filters, kernel_size, strides=strides, padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)
    x = Conv2D(filters, kernel_size, padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    if strides != 1 or shortcut.shape[-1] != filters:
        shortcut = Conv2D(filters, kernel_size=1, strides=strides, padding='same', kernel_regularizer=l2(weight_decay))(shortcut)
        shortcut = BatchNormalization()(shortcut)
    x = Add()([x, shortcut])
    x = tf.keras.layers.Activation('relu')(x)
    return x

def build_resnet_cifar100():
    weight_decay = 1e-4
    inputs = Input(shape=(32, 32, 3))
    x = Conv2D(64, kernel_size=3, padding='same', kernel_regularizer=l2(weight_decay))(inputs)
    x = BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)
    for _ in range(3):
        x = residual_block(x, 64)
    x = residual_block(x, 128, strides=2)
    for _ in range(2):
        x = residual_block(x, 128)
    x = residual_block(x, 256, strides=2)
    for _ in range(2):
        x = residual_block(x, 256)
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu', kernel_regularizer=l2(weight_decay))(x)
    x = Dropout(0.5)(x)
    outputs = Dense(100, activation='softmax', kernel_regularizer=l2(weight_decay))(x)
    return Model(inputs, outputs)

model = build_resnet_cifar100()
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('best_cifar100_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)
early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)

history = model.fit(
    datagen.flow(X_train, y_train, batch_size=128),
    epochs=150,
    validation_data=(X_test, y_test),
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)
print(f"\nTest accuracy: {test_acc:.4f}")

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss')

plt.tight_layout()
plt.savefig('cifar100_training_history.png')
plt.show()

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)
report = classification_report(y_true_classes, y_pred_classes)
print("\nClassification Report:\n", report)

def plot_confusion_matrix(y_true, y_pred, figsize=(18, 18)):
    cm = confusion_matrix(y_true, y_pred)
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    plt.figure(figsize=figsize)
    sns.heatmap(cm_norm, cmap="YlGnBu")
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('cifar100_confusion_matrix.png')
    plt.show()

# testing accuracies
# save model so api can use that

model.save('cifar100_model.h5')
print("Model saved to cifar100_model.h5")

import os
print("Current working directory:", os.getcwd())
print("Files in directory:", os.listdir())

